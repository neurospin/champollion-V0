{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import anatomist.api as ana\n",
    "from soma.qt_gui.qtThread import QtThreadCall\n",
    "from soma.qt_gui.qt_backend import Qt\n",
    "\n",
    "from soma import aims\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "existing QApplication: 0\n",
      "QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-jc225751'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create qapp\n",
      "global modules: /casa/host/build/share/anatomist-5.2/python_plugins\n",
      "home   modules: /casa/home/.anatomist/python_plugins\n",
      "done\n",
      "Starting Anatomist.....\n",
      "config file : /casa/home/.anatomist/config/settings.cfg\n",
      "PyAnatomist Module present\n",
      "PythonLauncher::runModules()\n",
      "loading module meshsplit\n",
      "loading module palettecontrols\n",
      "loading module volumepalettes\n",
      "loading module save_resampled\n",
      "loading module profilewindow\n",
      "loading module statsplotwindow\n",
      "loading module anacontrolmenu\n",
      "loading module infowindow\n",
      "loading module foldsplit\n",
      "loading module simple_controls\n",
      "loading module histogram\n",
      "loading module valuesplotwindow\n",
      "loading module ana_image_math\n",
      "loading module modelGraphs\n",
      "loading module paletteViewer\n",
      "loading module bsa_proba\n",
      "loading module gradientpalette\n",
      "loading module selection\n",
      "loading module gltf_io\n",
      "all python modules loaded\n",
      "Anatomist started.\n"
     ]
    }
   ],
   "source": [
    "a = ana.Anatomist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_file = \"/neurospin/dico/data/deep_folding/current/models/Champollion_V0/cluster/Sex_ukb_OLS_FColl-SRh_right_with-residualization.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "side = \"R\" # \"R\" or \"L\"\n",
    "region = \"F.Coll.-S.Rh.\" # \"S.C.-sylv.\", \"ORBITAL\", \"CINGULATE\", \"SC-sylv\", \"F.I.P.\"\n",
    "database='ukb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = pd.read_csv(f\"{cluster_file}\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_bucket(obj):\n",
    "    if obj.type() == obj.BUCKET:\n",
    "        return obj\n",
    "    avol = a.toAimsObject(obj)\n",
    "    c = aims.Converter(intype=avol, outtype=aims.BucketMap_VOID)\n",
    "    abck = c(avol)\n",
    "    bck = a.toAObject(abck)\n",
    "    bck.releaseAppRef()\n",
    "    return bck\n",
    "\n",
    "def build_gradient(pal):\n",
    "    gw = ana.cpp.GradientWidget(None, 'gradientwidget', pal.header()['palette_gradients'])\n",
    "    gw.setHasAlpha(True)\n",
    "    nc = pal.shape[0]\n",
    "    rgbp = gw.fillGradient(nc, True)\n",
    "    rgb = rgbp.data()\n",
    "    npal = pal.np['v']\n",
    "    pb = np.frombuffer(rgb, dtype=np.uint8).reshape((nc, 4))\n",
    "    npal[:, 0, 0, 0, :] = pb\n",
    "    npal[:, 0, 0, 0, :3] = npal[:, 0, 0, 0, :3][:, ::-1]  # BGRA -> RGBA\n",
    "    pal.update()\n",
    "\n",
    "def buckets_average(subject_id_list, dataset_name_list):\n",
    "    dic_vol = {}\n",
    "    dim = 0\n",
    "    rep = 0\n",
    "    if len(subject_id_list) == 0:\n",
    "        return False\n",
    "    while dim == 0 and rep < len(subject_id_list):\n",
    "        if dataset_name_list[rep].lower() in ['ukb', 'ukbiobank', 'projected_ukb']:\n",
    "            dataset = 'UkBioBank'\n",
    "        elif dataset_name_list[rep].lower() in ['hcp']:\n",
    "            dataset = 'hcp'\n",
    "        mm_skeleton_path = f\"/neurospin/dico/data/deep_folding/current/datasets/{dataset}/crops/2mm/{region}/mask/{side}crops\"\n",
    "        if os.path.isfile(f'{mm_skeleton_path}/{subject_id_list[rep]}_cropped_skeleton.nii.gz'):\n",
    "            sum_vol = aims.read(f'{mm_skeleton_path}/{subject_id_list[rep]}_cropped_skeleton.nii.gz').astype(float)\n",
    "            dim = sum_vol.shape\n",
    "            sum_vol.fill(0)\n",
    "        else: \n",
    "            print(f'FileNotFound {mm_skeleton_path}/{subject_id_list[rep]}_cropped_skeleton.nii.gz')\n",
    "            #raise FileNotFoundError(f'{mm_skeleton_path}/{subject_id_list[0]}_cropped_skeleton.nii.gz')\n",
    "        rep += 1\n",
    "\n",
    "    for subject_id, dataset in zip(subject_id_list,dataset_name_list):\n",
    "        if dataset.lower() in ['ukb', 'ukbiobank',  'projected_ukb']:\n",
    "            dataset = 'UkBioBank'\n",
    "        elif dataset.lower() == 'hcp':\n",
    "            dataset = 'hcp'\n",
    "            \n",
    "        mm_skeleton_path = f\"/neurospin/dico/data/deep_folding/current/datasets/{dataset}/crops/2mm/{region}/mask/{side}crops\"\n",
    "\n",
    "        if os.path.isfile(f'{mm_skeleton_path}/{subject_id}_cropped_skeleton.nii.gz'):\n",
    "            vol = aims.read(f'{mm_skeleton_path}/{subject_id}_cropped_skeleton.nii.gz')\n",
    "            # compare the dim with the first file dim\n",
    "\n",
    "            if vol.np.shape != dim:\n",
    "                raise ValueError(f\"{subject_id_list[0]} and {subject_id} must have the same dim\")\n",
    "\n",
    "                \n",
    "            # to have a binary 3D structure\n",
    "            dic_vol[subject_id] = (vol.np > 0).astype(int)\n",
    "            sum_vol.np[:] += (vol.np > 0).astype(int) \n",
    "        else: \n",
    "            print(f'FileNotFound {mm_skeleton_path}/{subject_id}_cropped_skeleton.nii.gz')\n",
    "            #raise FileNotFoundError(f'{mm_skeleton_path}/{subject_id}_cropped_skeleton.nii.gz')\n",
    "\n",
    "    sum_vol = sum_vol / len(subject_id_list)\n",
    "    print(sum_vol, sum_vol.shape)\n",
    "    return sum_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_averages_along_cluster(df, column_name, database, nb_subjects_per_average=200, nb_columns=5, nb_lines=1):\n",
    "    # anatomist objects\n",
    "    global _block\n",
    "    global _average_dic\n",
    "    global dic_packages\n",
    "    _average_dic = {}\n",
    "\n",
    "\n",
    "    # Order according to cluster\n",
    "    # Removes cluster 0, which is the non-cluster\n",
    "    df = df[df[column_name]!=0]\n",
    "    df = df.sort_values(column_name)\n",
    "    \n",
    "    # Computes umber of columns and number oif subjects per average\n",
    "    min_size = df.groupby(column_name).size().min()\n",
    "    nb_subjects_per_average = min(min_size, nb_subjects_per_average)\n",
    "    nb_columns = df[column_name].unique().shape[0]\n",
    "    print(f\"nb subjects per average = {nb_subjects_per_average}\")\n",
    "    \n",
    "    # Takes the first nb_subjects_per_average elements of each cluster\n",
    "    df = df.groupby(column_name, as_index=False).head(nb_subjects_per_average)\n",
    "    \n",
    "    cluster_number = df[[column_name]]\n",
    "    \n",
    "    # Creates block window with number of columns = nb of clusters\n",
    "    _block = a.createWindowsBlock(nb_columns)\n",
    "    nb_windows = nb_columns * nb_lines\n",
    "\n",
    "    # Creates dictionary of subjects to average\n",
    "    dic_packages = {}\n",
    "    for i in np.unique(cluster_number):\n",
    "        list_idx = cluster_number[cluster_number[column_name]==i].index.to_numpy()\n",
    "        dic_packages[i] = list_idx\n",
    "    \n",
    "    list_database = [database for i in range(nb_subjects_per_average)]\n",
    "    n_pack = len(dic_packages)\n",
    "\n",
    "    # Loop of display averages\n",
    "    list_pack = np.unique(cluster_number)\n",
    "    for i in list_pack:\n",
    "        sum_vol = buckets_average(dic_packages[i], list_database)\n",
    "        _average_dic[f'a_sum_vol{i}'] = a.toAObject(sum_vol)\n",
    "        _average_dic[f'a_sum_vol{i}'].setPalette(minVal=0, absoluteMode=True)\n",
    "        #wsum = a.createWindow('Sagittal', block=block)\n",
    "        #wsum.addObjects(a_sum_vol)\n",
    "        _average_dic[f'rvol{i}'] = a.fusionObjects(\n",
    "            objects=[_average_dic[f'a_sum_vol{i}']],\n",
    "            method='VolumeRenderingFusionMethod')\n",
    "        _average_dic[f'rvol{i}'].releaseAppRef()\n",
    "        # custom palette\n",
    "        n = len(dic_packages[i])\n",
    "        pal = a.createPalette('VR-palette')\n",
    "        pal.header()['palette_gradients'] = '0;0.459574;0.497872;0.910638;1;1#0;0;0.52766;0.417021;1;1#0;0.7;1;0#0;0;0.0297872;0.00851064;0.72766;0.178723;0.957447;0.808511;1;1'\n",
    "        #f'0;0.244444;0.5;1;1;1#0;0;0.535897;0.222222;1;1#0;0.7;1;0#0;0;{0.5/n};0;1;1'\n",
    "        build_gradient(pal)\n",
    "        _average_dic[f'rvol{i}'].setPalette('VR-palette', minVal=0.05, absoluteMode=True)\n",
    "        pal2 = a.createPalette('slice-palette')\n",
    "        pal2.header()['palette_gradients'] = '0;0.459574;0.497872;0.910638;1;1#0;0;0.52766;0.417021;1;1#0;0.7;1;0#0;0;0.0297872;0.00851064;0.72766;0.178723;0.957447;0.808511;1;1'\n",
    "        #f'0;0.244444;0.5;1;1;1#0;0;0.535897;0.222222;1;1#0;0.7;1;0#0;0;{0.3/n};0;{0.7/n};1;1;1'\n",
    "        build_gradient(pal2)\n",
    "        _average_dic[f'a_sum_vol{i}'].setPalette('slice-palette')\n",
    "        # rvol.palette().fill()\n",
    "        _average_dic[f'wvr{i}'] = a.createWindow('3D', block=_block)\n",
    "        _average_dic[f'wvr{i}'].addObjects(_average_dic[f'rvol{i}'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb subjects per average = 200\n",
      "<soma.aims.Volume_DOUBLE object at 0x756b74bb81f0> (34, 62, 41, 1)\n",
      "Multitexturing present\n",
      "function glActiveTexture found.\n",
      "function glClientActiveTexture found.\n",
      "function glBlendEquation found.\n",
      "function glTexImage3D found.\n",
      "function glMultiTexCoord3f found.\n",
      "function glBindFramebuffer found.\n",
      "function glBindRenderbuffer found.\n",
      "function glFramebufferTexture2D found.\n",
      "function glGenFramebuffers found.\n",
      "function glGenRenderbuffers found.\n",
      "function glFramebufferRenderbuffer found.\n",
      "function glRenderbufferStorage found.\n",
      "function glCheckFramebufferStatus found.\n",
      "function glDeleteRenderbuffers found.\n",
      "function glDeleteFramebuffers found.\n",
      "Number of texture units: 4\n",
      "function glUniform1f found.\n",
      "function glUniform1i found.\n",
      "function glUniform4fv found.\n",
      "function glGetUniformLocation found.\n",
      "function glMultTransposeMatrixf found.\n",
      "function glAttachShader found.\n",
      "function glDetachShader found.\n",
      "function glCompileShader found.\n",
      "function glCreateProgram found.\n",
      "function glCreateShader found.\n",
      "function glDeleteProgram found.\n",
      "function glDeleteShader found.\n",
      "function glGetProgramiv found.\n",
      "function glGetShaderiv found.\n",
      "function glLinkProgram found.\n",
      "function glShaderSource found.\n",
      "function glUseProgram found.\n",
      "GL_ARB_shadow present\n",
      "GL_SGIX_shadow present\n",
      "GL_SGIX_depth_texture extension present\n",
      "GL_ARB_depth_texture extension present\n",
      "GL_ARB_texture_cube_map extension present\n",
      "GL_EXT_texture_cube_map extension present\n",
      "Number of texture units: 4\n",
      "<soma.aims.Volume_DOUBLE object at 0x75695398dfc0> (34, 62, 41, 1)\n",
      "<soma.aims.Volume_DOUBLE object at 0x7569539a9d80> (34, 62, 41, 1)\n",
      "<soma.aims.Volume_DOUBLE object at 0x7569539b01f0> (34, 62, 41, 1)\n",
      "<soma.aims.Volume_DOUBLE object at 0x7569539b8040> (34, 62, 41, 1)\n"
     ]
    }
   ],
   "source": [
    "# block = a.createWindowsBlock(10)\n",
    "visualize_averages_along_cluster(cluster, \"cluster\", database, nb_subjects_per_average=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Displaying subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_subjects = list_smallest\n",
    "# block = a.createWindowsBlock(5) # 5 columns\n",
    "# dic_windows = {}\n",
    "# for subject in list_subjects:\n",
    "#     path_to_t1mri = f'/neurospin/dico/data/bv_databases/human/not_labeled/hcp/hcp/{subject}/t1mri/BL'\n",
    "#     dic_windows[f'w{subject}'] = a.createWindow(\"3D\", block=block)\n",
    "#     dic_windows[f'white_{subject}'] = a.loadObject(f'{path_to_t1mri}/default_analysis/segmentation/mesh/{subject}_{side}white.gii')\n",
    "#     dic_windows[f'white_{subject}'].loadReferentialFromHeader()\n",
    "#     dic_windows[f'sulci_{subject}'] = a.loadObject(f'{path_to_t1mri}/default_analysis/folds/3.1/{side}{subject}.arg')\n",
    "#     dic_windows[f'sulci_{subject}'].loadReferentialFromHeader()\n",
    "#     dic_windows[f'w{subject}'].addObjects([dic_windows[f'white_{subject}'], dic_windows[f'sulci_{subject}']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.sort_values(\"predicted\")[::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_concat = pd.concat([df.sort_values(\"predicted\")[::10][:5], df.sort_values(\"predicted\")[::10][-5:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no position could be read at 302, 258\n"
     ]
    }
   ],
   "source": [
    "# visualize_averages_along_parameter(df_concat, \"predicted\", database, nb_subjects_per_average=1, nb_columns=5, nb_lines=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
